{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, gc, re\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/enron-email-dataset/emails.csv')\n",
    "df.head(5)"
   ],
   "id": "318a20f0aa51a203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.iloc[22,1])",
   "id": "b7dcd3e02e4a44fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def info_part(i):\n",
    "    \"\"\"split infomation part out\"\"\"\n",
    "    return i.split('\\n\\n', 1)[0]\n",
    "def content_part(i):\n",
    "    \"\"\"split content part out\"\"\"\n",
    "    return i.split('\\n\\n', 1)[1]\n",
    "df['pre_info'] = df.message.map(info_part)\n",
    "df['content'] = df.message.map(content_part)\n",
    "df['test_true'] = True\n",
    "\n",
    "words2split = ['Message-ID: ', 'Date: ', 'From: ', 'To: ', 'Subject: ', 'Cc: ', 'Mime-Version: ', 'Content-Type: ',\n",
    "               'Content-Transfer-Encoding: ', 'Bcc: ', 'X-From: ', 'X-To: ', 'X-cc: ', 'X-bcc: ', 'X-Folder: ', 'X-Origin: ',\n",
    "               'X-FileName: ']\n",
    "features_naming = [i[:-2] for i in words2split]\n",
    "split_condition = '|'.join(words2split)"
   ],
   "id": "75c0685cffd7b334",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Some emails' subject confuse the string-spliting function, so I make a little change\n",
    "def duplicated_info(i):\n",
    "    return i.replace(' Date: ', ' Date- ').replace(' Subject: ', ' Subject2: ').replace(' To: ',\n",
    "                    ' To- ').replace(' (Subject: ', ' (Subject- ')\n",
    "df['pre_info'] = df['pre_info'].map(duplicated_info)\n",
    "\n",
    "# let's check how many categories are there in these emails\n",
    "def num_part(i):\n",
    "    return len(re.split(split_condition, i))\n",
    "df['num_info'] = df['pre_info'].map(num_part)\n",
    "\n",
    "# around 20k emails do not have the 'To: ' category, so I add one\n",
    "def add_to(i):\n",
    "    return i.replace('\\nSubject: ', '\\nTo: \\nSubject: ')\n",
    "temp_condition = (df['num_info'] == 17) | (df['num_info'] == 15)\n",
    "df.loc[temp_condition, 'pre_info'] = df.loc[temp_condition, 'pre_info'].map(add_to)\n",
    "\n",
    "\n",
    "# similar way to deal with the \"Cc:\" and \"Bcc:\" categories\n",
    "temp_condition = (df['num_info'] == 16) | (df['num_info'] == 15)\n",
    "def add_bcc(i):\n",
    "    return i.replace('\\nX-From: ', '\\nBcc: \\nX-From: ')\n",
    "df.loc[temp_condition, 'pre_info'] = df.loc[temp_condition, 'pre_info'].map(add_bcc)\n",
    "def add_cc(i):\n",
    "    return i.replace('\\nMime-Version: ', '\\nCc: \\nMime-Version: ')\n",
    "df.loc[temp_condition, 'pre_info'] = df.loc[temp_condition, 'pre_info'].map(add_cc)"
   ],
   "id": "85a38c3c773a49fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['num_info'] = df['pre_info'].map(num_part)\n",
    "df['num_info'].value_counts()"
   ],
   "id": "4f52e8e81c2e8c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "global feature_idx\n",
    "\n",
    "def info_split(i):\n",
    "    # Split the i th part out and remove \\n for the feature\n",
    "    split_results = re.split(split_condition, i)\n",
    "    if len(split_results) > feature_idx + 1:\n",
    "        return split_results[feature_idx + 1][:-2]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def info_split_last(i):\n",
    "    # No need to remove \\n for the last category -- X-FileName\n",
    "    split_results = re.split(split_condition, i)\n",
    "    if len(split_results) > feature_idx + 1:\n",
    "        return split_results[feature_idx + 1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Loop through each feature index\n",
    "for feature_idx in range(len(words2split)):\n",
    "    if feature_idx != len(words2split) - 1:\n",
    "        df[features_naming[feature_idx]] = df['pre_info'].map(info_split)\n",
    "    else:\n",
    "        df[features_naming[feature_idx]] = df['pre_info'].map(info_split_last)"
   ],
   "id": "d86e6548bcd17519",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Content-Transfer-Encoding'].value_counts()",
   "id": "5f58eaa5b0edb70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_remove2 = df.loc[df['Content-Transfer-Encoding'] == 'text/plain; charset=us-asci']\n",
    "df = df.loc[df['Content-Transfer-Encoding'] != 'text/plain; charset=us-asci']"
   ],
   "id": "470127fb79b8e35a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.loc[df[\"content\"].str.contains(\"-------------\"), \"content\"]",
   "id": "3478576d0de84e2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_other_content(i):\n",
    "    \"\"\"split other forms of contents out\"\"\"\n",
    "    return i.split('-------------', 1)[0]\n",
    "df[\"has_other_content\"] = df[\"content\"].str.contains(\"-------------\")\n",
    "df[\"if_forwarded\"] = df[\"content\"].str.contains(\"------------- Forwarded\")\n",
    "df['content'] = df.content.map(split_other_content)"
   ],
   "id": "c079e78f2f57706a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.drop(['pre_info','test_true', 'num_info'], axis = 1).set_index(\"file\")\n",
    "df.to_csv(\"emails_cleaned.csv\")"
   ],
   "id": "8dccf7c062591085",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(10)",
   "id": "513d2382eba945c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://www.kaggle.com/code/aakashsuresh2004/preprocessing-enron-datasets/notebook",
   "id": "909ee8c84eb1a262"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
